{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the data set:\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    " \n",
    "mnist_data = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "#The best part about downloading the data directly from Scikit-Learn is that it comes associated with a set of keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])\n"
     ]
    }
   ],
   "source": [
    "print(mnist_data.keys())\n",
    "\n",
    "#basically, we get the `data` and target already separated. That makes the job much easier now\n",
    "#You can also see the description by using the DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (70000, 784) \n",
      " Shape of y: (70000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = mnist_data['data'], mnist_data['target']\n",
    "print('Shape of X:', X.shape, '\\n', 'Shape of y:', y.shape)\n",
    "\n",
    "#So the data key contains 70000 rows and 784 columns. \n",
    "#These columns all contain the pixel intensities of the handwritten numbers ranging from 0 to 255 which are of 28 x 28 (784) images. \n",
    "#the target key contains all the labels from 0 to 9 corresponding to the data key pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us take a look at the first few digits that are in the data set. \n",
    "#For this, you will be using the popular matplotlib library.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "digit = X[0]\n",
    "digit_pixels = digit.reshape(28, 28)\n",
    "plt.subplot(131)\n",
    "plt.imshow(digit_pixels)\n",
    "plt.axis('off')\n",
    " \n",
    "digit = X[1]\n",
    "digit_pixels = digit.reshape(28, 28)\n",
    "plt.subplot(132)\n",
    "plt.imshow(digit_pixels)\n",
    "plt.axis('off')\n",
    " \n",
    "digit = X[2]\n",
    "digit_pixels = digit.reshape(28, 28)\n",
    "plt.subplot(133)\n",
    "plt.imshow(digit_pixels)\n",
    "plt.axis('off')\n",
    "\n",
    "#We reshaped the images from 1-D arrays to 28 x 28 matrices. \n",
    "#Then, we observe that we used plt.imshow(). Actually, that takes an array image data and plots the pixels on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us check whether the plots are correct or not.\n",
    "\n",
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the target label of y[2] is 4 as well, but with one caveat. The target label is a string. \n",
    "#It is better to convert the labels to integers as it will help further on in this guide.\n",
    "\n",
    "# Changing the labels from string to integers\n",
    "import numpy as np\n",
    "y = y.astype(np.uint8)\n",
    "y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating The Training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] \n",
      " Test Data: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] \n",
      " Train label:  [5 0 4 ... 5 6 8] \n",
      " Test Label:  [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "#Next goal is to make a separate test set which the model will not see until the test phase is reached in the process.\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "print('Train Data: ', X_train, '\\n', 'Test Data:', X_test, '\\n',\n",
    "     'Train label: ', y_train, '\\n', 'Test Label: ', y_test)\n",
    "\n",
    "#60000 image instances as the train data and 10000 for the testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will be using the Stochastic Gradient Descent classifier (SGD)\n",
    "Scikit-Learn’s SGDClassifier is a good place to start for linear classifiers. \n",
    "Using the loss parameter we will see how Support Vector Machine (Linear SVM) and Logistic Regression perform for the same dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To use the Linear SVM Classifier you have to set the loss parameter to hinge\n",
    "#This is also set to linear SVM by default if you do not set it on your own.\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    " \n",
    "sgd_clf = SGDClassifier(loss='hinge', random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "#This took 3mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87365, 0.85835, 0.8689 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now that you have fit your model, before moving on to testing it, \n",
    "#let’s first see the cross-validation scores on the training data. \n",
    "#That you will give you a very good projection of how the model performs.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "#This took 4mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For three-fold Cross-Validation you are getting around 87% – 88% accuracy. \n",
    "#Not too bad, not too good either. Now let’s see the actual test scores.\n",
    "\n",
    "score = sgd_clf.score(X_test, y_test)\n",
    "score\n",
    "\n",
    "#We are getting 84% accuracy. \n",
    "#Okay, looks like the model generalized a bit worse than the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To classify using the Logistic Regression you have to set loss to log.\n",
    "\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log', random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "#This took 3mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8691 , 0.87985, 0.87845])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "#This took 5mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8772"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sgd_clf.score(X_test, y_test)\n",
    "score\n",
    "\n",
    "#Interesting, although the cross-validation scores are not as good as linear SVM, but we are getting better test scores. \n",
    "#It is not too high this time as well, but still there is a slight improvement from about 84% to about 89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see that there is much room for improvement. \n",
    "You should consider using some other classifiers like the K – Nearest Neighbor (KNN). It may give better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://debuggercafe.com/image-classification-with-mnist-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
